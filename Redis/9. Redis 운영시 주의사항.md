# Cache stempede
* 특정 cache entry 의 TTL 이 만료되었을때, 해당 entry 로의 조회 요청이 동시에 다량 인입될경우, 해당 요청들은 모두 cache miss 됨
* 그로인해 Data Source(DB 또는 2차 cache) 로의 다량의 중복 조회 요청 및 중복 cache write 가 수행되는 문제 발생

![image](https://github.com/user-attachments/assets/ce8f40ff-9660-47eb-9996-5af963277ca3)

### Solution 
* PER(Probablistic Early Recomputation)
  * TTL이 만료되기 전에 일정 확률로 캐시를 미리 갱신하는 방법 
* Debouncing (a.k.a Collapsed Forwarding)
  * 단위시간 내에 인입된 동일한 캐시 조회 요청들을 묶어 하나의 요청처럼 처리함으로서 중복된 데이터 처리나 네트워크 호출을 줄이는 방법
  * Cache miss 일 경우, Data Source 로의 조회 요청은 한번만 수행하고 나머지 캐시 조회 요청들은 대기, Data Source 로부터 응답 수신하여 캐싱 후 처리 재개


# Hot Cache
* Redis Cluster 에서 특정 키에 대한 요청이 집중적으로 발생하여 해당 키가 저장되어있는 특정 노드에만 부하가 집중되는(Hot Spot) 부하 불균형 문제 발생

### Solution
* 키샤딩
  * 하나의 키를 여러 개의 샤드로 분할하여 여러 클러스터 노드에 분산 저장
  * key 앞에 클러스터 노드 수만큼 prefix 추가, 해당 prefix 를 hashtag 로 사용하여 각 클러스터 노드에 분산 저장
    * hashtag 가 다를시, 서로 다른 hash slot 에 저장됨이 100% 보장되지는 않음 (하지만, Redis 의 해시함수는 collsion을 최소화하도록 설계되었기때문에, 대부분 서로다른 hash slot 에 저장됨)
  * key 조회시, random(혹은 round-robin) 하게 prefix 선택하여 조회
  * 데이터 일관성 유지가 복잡해지는 단점 존재
* 슬레이브 조회
  * 클라이언트에서 슬레이브 노드들로 조회 요청 분산
    * `Lettuce` 의 `read-from=REPLICA_PREFERRED` 설정을 통해 이같은 기능 지원
  * 데이터 일관성 유지가 간단해짐

# Thundering Herd Problem
* 클라이언트가 동시에 동일한 리소스에 접근하려고 할 때 발생하는 문제입니다. 이는 특히 리소스가 잠금 상태에 있을 때 나타나며, 잠금이 해제되면 모든 대기 중인 클라이언트가 동시에 리소스에 접근하여 시스템에 과부하를 초래할 수 있습니다.

### Solution
* 요청을 큐에 넣어 순차적으로 처리하거나, 뮤텍스를 사용하여 접근을 제어하는 방법이 있습니다. 


# Dogpile Effect
* 캐시가 만료된 후, 여러 클라이언트가 동시에 데이터베이스에 접근하여 데이터를 갱신하려고 할 때 발생하는 문제입니다. 이는 캐시 스탬피드와 유사하지만, 주로 캐시 만료 시점에 집중됩니다.

### Solution
* 캐시 만료 전에 백그라운드에서 데이터를 갱신하거나, 첫 번째 요청만 데이터베이스에 접근하도록 제한하는 방법이 있습니다.


# Cache Miss Storm
* 캐시 적중률이 낮아져 많은 요청이 데이터베이스로 전달되는 상황을 의미합니다. 이는 캐시 크기가 작거나, 캐시 정책이 비효율적인 경우에 발생할 수 있습니다.

### Solution
* 캐시 크기 조정, LRU(Least Recently Used)와 같은 적절한 캐시 정책 사용을 통해 개선할 수 있습니다.


# Cold Start Problem
* 시스템 시작 시 캐시가 비어 있어 모든 요청이 데이터베이스로 전달되는 상황을 의미합니다. 이는 초기 부하를 증가시키고, 시스템 성능을 저하시킬 수 있습니다.

### Solution
* 시스템 시작 시 자주 사용되는 데이터를 미리 캐시에 로드하거나, 캐시 프리로딩(preloading)을 통해 문제를 완화할 수 있습니다. 
* 이러한 문제들은 시스템 설계와 운영에서 자주 고려해야 할 요소들입니다. 각 문제에 대한 적절한 해결책을 적용함으로써 시스템의 성능과 안정성을 높일 수 있습니다.


> Reference
> * https://velog.io/@xogml951/Hot-key%EC%97%90%EC%84%9C-Cache-Stampede%EC%99%80-Probabilistic-Early-Recomputation-%EC%A0%81%EC%9A%A9
> * https://news.hada.io/topic?id=2777
> * https://velog.io/@qlgks1/NHN-FORWARD-Redis-%EC%95%BC%EB%AC%B4%EC%A7%80%EA%B2%8C-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0
> * https://architecturenotes.co/p/redis
> * https://meetup.nhncloud.com/posts/251
> * https://engineering.linecorp.com/ko/blog/atomic-cache-stampede-redis-lua-script
> * https://zdnet.co.kr/view/?no=20131119174125
> * https://engineering.linecorp.com/ko/blog/how-line-openchat-server-handles-extreme-traffic-spikes
> * https://esperer.tistory.com/76
