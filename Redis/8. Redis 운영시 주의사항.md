# Cache stempede
* 특정 cache entry 의 TTL 이 만료되었을때, 해당 entry 로의 조회 요청이 동시에 다량 인입될경우, 해당 요청들은 모두 cache miss 됨
* 그로인해 Data Source(DB 또는 2차 cache) 로의 다량의 중복 조회 요청 및 중복 cache write 가 수행되는 문제 발생

![image](https://github.com/user-attachments/assets/ce8f40ff-9660-47eb-9996-5af963277ca3)

### Solution 
* PER(Probablistic Early Recomputation)
  * TTL이 만료되기 전에 일정 확률로 캐시를 미리 갱신하는 방법 
* Debouncing (a.k.a Collapsed Forwarding)
  * 단위시간 내에 인입된 동일한 캐시 조회 요청들을 묶어 하나의 요청처럼 처리함으로서 중복된 데이터 처리나 네트워크 호출을 줄이는 방법
  * Cache miss 일 경우, Data Source 로의 조회 요청은 한번만 수행하고 나머지 캐시 조회 요청들은 대기, Data Source 로부터 응답 수신하여 캐싱 후 처리 재개


# Hot Cache
* Redis Cluster 에서 특정 키에 대한 요청이 집중적으로 발생하여 해당 키가 저장되어있는 특정 노드에만 부하가 집중되는(Hot Spot) 부하 불균형 문제 발생

### Solution
* 키샤딩
  * 하나의 키를 여러 개의 샤드로 분할하여 여러 클러스터 노드에 분산 저장
  * key 앞에 클러스터 노드 수만큼 prefix 추가, 해당 prefix 를 hashtag 로 사용하여 각 클러스터 노드에 분산 저장
  * key 조회시, random(혹은 round-robin) 하게 prefix 선택하여 조회


# 메모리 단편화
* Redis 에서 크기가 작은 엔트리등이 많이 저장 및 삭제 반복시 메모리 단편화 발생 가능
* Redis 는 메모리 단편화를 최소화하기 위한 다양한 메모리 할당기 사용 가능. 대표적으로 jemalloc
* 그럼에도 불구하고 메모리 단편화 발생 가능. Redis 는 현재 메모리 단편화 정도를 알 수 있는 다양한 지표 제공 (`redis-cli` 의 INFO 명령어를 통해 확인 가능)
  * used_memory_rss(resident set size)
    * OS 가 Redis에게 할당한 메모리 양
  * used_memory
    * Redis가 실제 사용하고 있는 메모리 양
  * mem_fragmentation_ratio
    * used_memory_rss / used_memory
    * 메모리 단편화가 심할경우 이 값이 1.5 이상으로 나타남
    * Redis 에 대한 peak 트래픽과 평균 트래픽 차이가 클경우, peak 트래픽을 위해 할당된 메모리 양은 높으면서 실제 평균 사용하는 메모리 양은 낮아 이 값이 1.5 이상으로 나타날 수 있다. 이런경우 예외적으로 정상인 상황

### Solution 
* 메모리 단편화 해소를 위해 Redis 를 재시작 하거나 혹은 Redis 에서 제공하는 activefrag 기능 사용
  * 일명 조각모음으로서, Redis 가 단편화된 메모리 블록을 재배치하여 단편화 해소 
  * 런타임중에 동작하여 Redis 가 메모리 사용 패턴을 모니터링하여 자동으로 activefrag 수행 (동작중엔 cpu 사용량 다소 증가 가능)
  * 기본적으로 비활성화 되어있음. `redis-cli`에서 `CONFIG SET activedefrag yes` 를 입력하여 활성화 가능


# Thundering Herd Problem
* 클라이언트가 동시에 동일한 리소스에 접근하려고 할 때 발생하는 문제입니다. 이는 특히 리소스가 잠금 상태에 있을 때 나타나며, 잠금이 해제되면 모든 대기 중인 클라이언트가 동시에 리소스에 접근하여 시스템에 과부하를 초래할 수 있습니다.

### Solution
* 요청을 큐에 넣어 순차적으로 처리하거나, 뮤텍스를 사용하여 접근을 제어하는 방법이 있습니다. 


# Dogpile Effect
* 캐시가 만료된 후, 여러 클라이언트가 동시에 데이터베이스에 접근하여 데이터를 갱신하려고 할 때 발생하는 문제입니다. 이는 캐시 스탬피드와 유사하지만, 주로 캐시 만료 시점에 집중됩니다.

### Solution
* 캐시 만료 전에 백그라운드에서 데이터를 갱신하거나, 첫 번째 요청만 데이터베이스에 접근하도록 제한하는 방법이 있습니다.


# Cache Miss Storm
* 캐시 적중률이 낮아져 많은 요청이 데이터베이스로 전달되는 상황을 의미합니다. 이는 캐시 크기가 작거나, 캐시 정책이 비효율적인 경우에 발생할 수 있습니다.

### Solution
* 캐시 크기 조정, LRU(Least Recently Used)와 같은 적절한 캐시 정책 사용을 통해 개선할 수 있습니다.


# Cold Start Problem
* 시스템 시작 시 캐시가 비어 있어 모든 요청이 데이터베이스로 전달되는 상황을 의미합니다. 이는 초기 부하를 증가시키고, 시스템 성능을 저하시킬 수 있습니다.

### Solution
* 시스템 시작 시 자주 사용되는 데이터를 미리 캐시에 로드하거나, 캐시 프리로딩(preloading)을 통해 문제를 완화할 수 있습니다. 
* 이러한 문제들은 시스템 설계와 운영에서 자주 고려해야 할 요소들입니다. 각 문제에 대한 적절한 해결책을 적용함으로써 시스템의 성능과 안정성을 높일 수 있습니다.


> Reference
> * https://velog.io/@xogml951/Hot-key%EC%97%90%EC%84%9C-Cache-Stampede%EC%99%80-Probabilistic-Early-Recomputation-%EC%A0%81%EC%9A%A9
> * https://news.hada.io/topic?id=2777
> * https://velog.io/@qlgks1/NHN-FORWARD-Redis-%EC%95%BC%EB%AC%B4%EC%A7%80%EA%B2%8C-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0
> * https://architecturenotes.co/p/redis
> * https://meetup.nhncloud.com/posts/251
> * https://engineering.linecorp.com/ko/blog/atomic-cache-stampede-redis-lua-script
> * https://zdnet.co.kr/view/?no=20131119174125
> * https://engineering.linecorp.com/ko/blog/how-line-openchat-server-handles-extreme-traffic-spikes
> * https://esperer.tistory.com/76
