# 처리율 제한 장치 설계

## 1. 요구사항 파악
* 다음의 질문들이 가능하다
  * 어떤 식별자를 기준으로 제한할지?(userId / clientIp / sessionId / api)
  * 제한할 시간 단위는 뭔지?(초당/분당/시간당)
  * 분산 환경에서 동작해야하는지?
  * 100% 정확하게 제한해야하는지(hard rate limiter)? 아니면 약간의 오차는 허용하는지(soft rate limiter)
  * 개략적인 TPS 는 어느정도 될지?
  * 인하우스 플랫폼엔 어떤것들이 있는지?(kafka, redis 등등..) 혹은 이러한 제한을 고려하지 않아도 되는지?
  * rate limiter 에 걸린 요청에 대한 처리는 어떻게 해야하는지? (429 에러 응답 / MQ 에 저장해뒀다가 추후 처리)
  * 제한 단위는 초당? 분당? 시간당?

## 2. 개략적인 설계안 제시
### rate-limiter 위치
* 서버
  * 웹서버에 rate-limiter 구현
* 미들웨어
  * 웹서버 앞단에 rate-limiter 를 reverse proxy 로 설치 

### rate-limit 알고리즘
#### token bucket
* 알고리즘
  * 서버마다 버킷에 정해진 양만큼의 토큰을 가지고있음
    * api 마다 별도의 버킷 소유
  * 토큰은 일정 시간 간격으로 하나씩 리필
    * 정해진 양만큼의 토큰이 버킷에 모두 채워져있다면, 리필된 토큰은 버림
  * 요청 하나당, 하나의 토큰을 소비
    * 토큰이 버킷에 한개도 남아있지 않다면, 요청 차단
* 파라미터
  * 버킷 크기
  * 토큰 공급률 (단위 시간당 토큰 공급률)
* 장점
  * 적은 메모리 사용량
  * 일시적으로 많은 트래픽이 몰려도 처리 가능
* 단점
  * 버킷 크기, 토큰 공급률 2가지 파라미터만 가지고 섬세한 액세스 속도 제어가 힘듦

#### leaky bucket
* 알고리즘
  * 각 서버 api 마다 고정된 크기의 큐를 가지고있음
  * 요청 인입시, 큐에 빈공간이 있다면 해당 공간에 요청을 enqueue
    * 빈공간이 없다면, 요청 차단
  * 정해진 시간마다 큐에서 요청을 dequeue 하여 처리
* 파라미터
  * 큐 크기
  * 처리율 (단위 시간당 처리할 요청 개수)
* 장점
  * 적은 메모리 사용량
  * 요청량에 상관없이 항상 처리율로 설정한 양만큼만 요청을 처리하기때문에 안정적 출력
* 단점
  * 일시적으로 많은 트래픽이 몰릴경우, 큐에 해당 요청들로 가득차게되고 일정시간동안 새로운 요청들이 계속 차단되는 상황 발생

#### fixed window counter
* 알고리즘
  * 고정된 시간 간격(window)마다 counter 를 가지고 요청량 집계
  * 요청 인입시, 현재 window의 카운터값 1 증가시키고 요청 처리
  * 현재 window 의 카운터값이 임계값 이상일 경우, 요청 차단
* 파라미터
  * windown 크기 (시간 간격)
  * 요청량 임계값
* 단점
  * 윈도우 경계부근에 요청이 몰릴 경우, 단위 시간당 요청량 입계값보다 더 많은 요청을 서버가 처리하게 되는 오차 발생

#### sliding window logging
* fixed windown counter 의 단점을 보완한 정밀한 rate limiting 알고리즘
* 알고리즘
  * 고정된 시간 간격(window) 마다 요청량 집계하는것은 동일하나, 요청수만 기록하는것이 아닌, 요청이 인입된 시간을 함께 기록
  * 요청 인입시, 인입된 시간을 기준으로 window 를 설정. window 내에 요청수가 임계값 이상일 경우, 요청 차단
* 파라미터
  * windown 크기 (시간 간격)
  * 요청량 임계값
* 장점
  * 윈도우 경계부근에 요청이 몰려도, 새로운 요청이 인입된 시간을 기준으로 window 를 설정하기 때문에 정밀한 요청량 집계 가능
* 단점
  * 허용된 요청, 차단된 요청 모두 기록해야 하기 때문에 메모리 사용량이 높음

#### sliding window counter
* fixed window counter 의 단점과 sliding window logging 의 단점을 모두 보완한 알고리즘
* 알고리즘
  * 고정된 시간 간격(window) 마다 요청량 집계하는것은 동일하나, 좀 더 복잡한 아래의 공식을 통해 요청량 집계
    * 현재 window 의 요청수 + (직전 window 의 요청수 * 요청 인입된 시간 기준 window 와 직전 window 가 겹치는 비율)
* 장점
  * 허용된 요청만 기록하기때문에 적은 메모리 사용량
  * 윈도우 경계부근에 요청이 몰리거나 일시적으로 많은 요청이 몰리는 경우에도 정밀하게 동작

### 분산 환경의 rate-limiter
* 웹서버가 여러개인 분산환경인 경우, 공유 저장소에서 요청량을 집계해야함 --> 보통 빠른 조회 및 수정 속도를 보장하는 Redis cache 를 사용 
* Redis cache 를 사용할경우, 캐시 조회 및 +1 증가의 작업이 원자적으로 수행되어야함. lua script 를 통해 원자적으로 수행 가능
* Redis 가 아무리 빠르다 해도, 요청량이 매우 많을경우 병목이 발생할 것이다. 그럴경우 local cache 와 함께 사용하거나 Redis 클러스터를 이용해 캐시 샤딩하여 부하 분산
  * Redis 클러스터를 이용해 캐시 샤딩시 hotspot key 문제 발생 가능. hotspot key 가 되는 요청은 해싱을 통해 여러 키로 분할하여 분산 저장(Global Counter 를 통해 빠른 조회)

### 처리율 초과 요청 처리
* 429 Too many requests 에러를 응답
  * 에러 응답과 함께 처리율 제한에 걸리지 않으려면 몇초뒤에 다시 요청해야하는지(retry-backoff-millis) 시간값과 함께 응답 (X-Ratelimit-Retry-After)
* Kafka 와 같은 MQ 에 저장해뒀다가 추후 처리
  * 상품 주문 요청이 처리율 초과에 걸린경우, MQ 에 저장했다가 나중에 주문 처리

## 3. 상세설계

![image](https://github.com/user-attachments/assets/9e3b469e-d2ce-4b20-87cc-c06fdc1b5558)

### 장점
* Sliding windown counter 알고리즘을 이용해 window 경계부근에 요청이 몰림으로 인한 오차 최소화
* Global cache + Local cache 함께 사용함으로서 Global cache IO 로 인한 쓰루풋 감소 최소화

### 단점
* Redis 운영 비용
* 약간의 오차 발생 가능(x * (n-1))
  * x 값을 줄일시, 오차는 줄어들지만 redis 조회 횟수가 많아짐
  * x 값 늘릴시, redis 조회 횟수는 줄어들지만 오차가 커짐
  * 운영을 통해 적절한 x값 도출


> Reference
> * https://learn.microsoft.com/en-us/azure/architecture/patterns/rate-limiting-pattern
> * https://www.tryexponent.com/blog/rate-limiter-system-design
> * https://12bme.tistory.com/547
